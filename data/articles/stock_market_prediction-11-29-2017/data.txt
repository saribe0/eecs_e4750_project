https://www.nytimes.com/2017/11/28/us/politics/homeland-security-personal-data-software-stolen.html

By NICHOLAS FANDOS and RON NIXONNOV. 28, 2017
 WASHINGTON — It was an audacious scheme: an attempted inside job at the office of a federal watchdog agency, where the cops, the authorities said, became the robbers. Three employees in the inspector general’s office for the Department of Homeland Security stole a computer system that contained sensitive personal information of about 246,000 agency employees, according to three United States officials and a report sent to Congress last week. They planned to modify the office’s proprietary software for managing investigative and disciplinary cases so that they could market and sell it to other inspector general offices across the federal government. The Homeland Security Department is investigating, along with the United States attorney’s office for the District of Columbia. The personal information included names, social security numbers and dates of birth — a rich trove of data not unlike those stolen from other government agencies in high-profile cases in recent years. On the home computer of one of the suspects that was seized during a raid in the spring, investigators also found about 159,000 case files. Advertisement But investigators determined the private information was not, in fact, their target. Investigators believe the suspects intended to use the data to “facilitate the development and testing of” their knockoff system, according to the report. What you need to know to start your day, delivered to your inbox Monday through Friday. Please verify you're not a robot by clicking the box. Invalid email address. Please re-enter. You must select a newsletter to subscribe to. View all New York Times newsletters. In May, the office of the inspector general, John Roth, first notified several congressional committees with oversight of the Homeland Security Department, including the committees for homeland security, appropriations and commerce. Additional updates were sent to those panels in June and another last week. Advertisement Mr. Roth did not identify the employees, one of whom has left the office, and the American officials, who spoke on the condition of anonymity to discuss a continuing case, declined to name them. The two current employees have been suspended pending the results of the investigation. In its report to Congress, Mr. Roth’s office said that it had “seized all known servers and other devices potentially containing exfiltrated data in the possession of the subjects.” A spokesman for the Department of Homeland Security declined to comment on Tuesday about the investigation. William Miller, a spokesman for the United States attorney’s office in Washington, said he could not confirm or deny the existence of an investigation. The breach was earlier reported by USA Today. In the past two years, several government agencies, including the Internal Revenue Service, the Securities and Exchange Commission, the State Department and the National Security Agency, have had data stolen, American officials said. The most significant case was in 2015, when hackers linked to the Chinese military stole records connected to more than 21 million government employees, including those with high-level security clearances. The acting secretary for homeland security, Elaine Duke, elected in August to notify victims of the breach and the department is in the process of doing so, according to its most recent report to Congress. In recent weeks, the department has asked its component agencies to try to find additional money from their budgets to cover the hundreds of thousands of dollars needed to to monitor the credit scores of affected employees, according to an official familiar with the request. Get politics and Washington news updates via Facebook, Twitter and the Morning Briefing newsletter. A version of this article appears in print on November 29, 2017, on Page A15 of the New York edition with the headline: At Security Department, Inside Job Goes Awry.  Order Reprints| Today's Paper|Subscribe

 We’re interested in your feedback on this page. Tell us what you think. See More » 

https://www.nytimes.com/2017/11/28/us/politics/homeland-security-personal-data-software-stolen.html

By NICHOLAS FANDOS and RON NIXONNOV. 28, 2017
 WASHINGTON — It was an audacious scheme: an attempted inside job at the office of a federal watchdog agency, where the cops, the authorities said, became the robbers. Three employees in the inspector general’s office for the Department of Homeland Security stole a computer system that contained sensitive personal information of about 246,000 agency employees, according to three United States officials and a report sent to Congress last week. They planned to modify the office’s proprietary software for managing investigative and disciplinary cases so that they could market and sell it to other inspector general offices across the federal government. The Homeland Security Department is investigating, along with the United States attorney’s office for the District of Columbia. The personal information included names, social security numbers and dates of birth — a rich trove of data not unlike those stolen from other government agencies in high-profile cases in recent years. On the home computer of one of the suspects that was seized during a raid in the spring, investigators also found about 159,000 case files. Advertisement But investigators determined the private information was not, in fact, their target. Investigators believe the suspects intended to use the data to “facilitate the development and testing of” their knockoff system, according to the report. What you need to know to start your day, delivered to your inbox Monday through Friday. Please verify you're not a robot by clicking the box. Invalid email address. Please re-enter. You must select a newsletter to subscribe to. View all New York Times newsletters. In May, the office of the inspector general, John Roth, first notified several congressional committees with oversight of the Homeland Security Department, including the committees for homeland security, appropriations and commerce. Additional updates were sent to those panels in June and another last week. Advertisement Mr. Roth did not identify the employees, one of whom has left the office, and the American officials, who spoke on the condition of anonymity to discuss a continuing case, declined to name them. The two current employees have been suspended pending the results of the investigation. In its report to Congress, Mr. Roth’s office said that it had “seized all known servers and other devices potentially containing exfiltrated data in the possession of the subjects.” A spokesman for the Department of Homeland Security declined to comment on Tuesday about the investigation. William Miller, a spokesman for the United States attorney’s office in Washington, said he could not confirm or deny the existence of an investigation. The breach was earlier reported by USA Today. In the past two years, several government agencies, including the Internal Revenue Service, the Securities and Exchange Commission, the State Department and the National Security Agency, have had data stolen, American officials said. The most significant case was in 2015, when hackers linked to the Chinese military stole records connected to more than 21 million government employees, including those with high-level security clearances. The acting secretary for homeland security, Elaine Duke, elected in August to notify victims of the breach and the department is in the process of doing so, according to its most recent report to Congress. In recent weeks, the department has asked its component agencies to try to find additional money from their budgets to cover the hundreds of thousands of dollars needed to to monitor the credit scores of affected employees, according to an official familiar with the request. Get politics and Washington news updates via Facebook, Twitter and the Morning Briefing newsletter. A version of this article appears in print on November 29, 2017, on Page A15 of the New York edition with the headline: At Security Department, Inside Job Goes Awry.  Order Reprints| Today's Paper|Subscribe

 We’re interested in your feedback on this page. Tell us what you think. See More » 

https://www.statnews.com/2017/11/29/big-data-analysis-health/

Your daily dose of news in health and medicine. 

https://www.statnews.com/2017/11/29/big-data-analysis-health/

Your daily dose of news in health and medicine. 

https://www.scientificamerican.com/article/is-the-fda-withholding-data-about-a-controversial-drug-to-protect-its-manufacturer/

In the case of Sarepta, it sure looks that way The Food and Drug Administration is seldom accused of being too transparent. But in late September, it looked like the agency had overshared. In an attempt to achieve the "greatest level of transparency," the agency caused the stock prices of four biotech companies to hemorrhage. Jittery traders, sifting through scraps of context-free information provided by the agency, dumped their drug stocks, triggering a brief but brutal plunge. It shouldn't have happened that way. The FDA's attempt at transparency was far from revolutionary; it was the release of a Web interface to a drug side-effects database known as FAERS. Not only was FAERS already public, albeit in a slightly less user-friendly form, the database is also messy, context-free and subject to all sorts of biases and errors, making it nigh impossible to interpret properly. It's not something that the public should be very excited about; FAERS certainly isn't a precise enough tool to tell market speculators whether to dump a stock, any more than a sledgehammer is a precise enough tool to amputate a limb. Yet soon after the FDA announced the new interface, the stocks of four companies—Sarepta, Ionis, Biogen, and Acadia—plunged. The underlying cause of the bloodbath, ironically, is the FDA's opacity regarding certain important data about the performance of drugs. Data about adverse events patients had when taking the drug. Data that can give us insight into what elements of a clinical study researchers haven't made public. Even data hinting at research misconduct in key drug trials. The agency refuses to release this data, yet without it, the public is unable make an informed decision about whether or not to take a drug. The reason: doing so might hurt a pharmaceutical company. FDA's refusal is a graphic demonstration of how the agency feels obliged to protect corporate secrets, even at the expense of consumer safety. That's the precise opposite of transparency, and in the FDA's case, it might be putting people's lives at risk. *** The FDA has the unenviable position of making life-and-death decisions every day. No matter how good the agency is, some of the time, it's going to get a decision wrong, and Americans will be put at risk and even die. When things go wrong, though, it's often damnably hard to figure out precisely what happened. The FDA has long had a reputation for opacity; even congresspeople, who have the power of subpoena, have been frustrated by the agency's refusal to provide basic information that could help reveal the true story behind a bad decision. A decade ago, Senator Charles Grassley (R-Iowa), when looking into a case where the FDA made a bad call in approving a dangerous drug, said the FDA put up "every excuse under the sun" to prevent the release of requested documents: “The Department [of Health and Human Services] and FDA say that they have been responsive to the Finance Committee's Ketek investigation because they made available millions of pages of documents to the Committee. But what they provided is quantity, not quality. “They delivered hundreds of pages simply marked, for example, ‘57 pages removed,’ or ‘43 pages removed.... Other documents have whole pages, paragraphs or sentences redacted with no explanation for what has been withheld or redacted and why. In fact, the FDA redacted some of the same documents differently and even redacted one of my own letters to them on a different matter....” Reporters like me have encountered similar roadblocks when covering the FDA. (For example, when I was trying to investigate how the agency was handling a massive case of fraud that undermined the data behind a number of approvals, the agency refused to release the names of the drugs that were affected.) On occasion, the agency is not just slow to release information about problems it's finding with drugs, but it has even been willing to reassure the public about products that later turn out to be dangerous. So the public can't rely upon the agency to release everything that's important to know, and objective data that the agency uses to make its decisions have become quite valuable for understanding not just the FDA's decision process but also whether it's been making good calls or bad ones. *** It so happens that one of the most controversial calls of the past few years has to do with one of the companies involved in September's stock plunge, Sarepta. A little over a year ago, the FDA decided to approve Sarepta's first drug, eteplirsen.  Eteplirsen is a cleverly designed compound that's supposed to help certain patients with Duchenne muscular dystrophy (DMD), a deadly disease that strikes young boys. Initially, the FDA's answer was that the drug should be rejected, but Janet Woodcock, the head of the agency's Center for Drug Evaluation and Research overruled the agency's own review team, a very unusual step, and declared that the drug should be allowed to come to market. Since then, a cloud has hung over eteplirsen as third parties, such as insurers, physicians and independent researchers, try to figure out whether or not the drug actually works. The agency has released thousands of pages of information about eteplirsen, but I knew that there was a lot of critical information missing from those pages—information that might help determine whether the agency approved an entirely ineffective drug based on faulty clinical trials and undue industry influence, or whether there is unjust suspicion about eteplirsen's safety and effectiveness. Earlier this year, I sued the FDA under the Freedom of Information Act to understand the eteplirsen decision better; the lawsuit was designed to force the agency to release information about the drug and the agency's decision. In the past several weeks, the agency has released thousands of pages of previously undisclosed documents about eteplirsen and its approval, and more are coming before the end of the year. Despite the volumes of papers the FDA is disclosing, once again, the FDA is far from transparent. What's so striking in those documents is not the information that FDA is releasing, but the information that the agency refuses to release.                 For example, in several of the documents, frequently encountered adverse events—side effects and other negative consequences that occur during a treatment—are occasionally redacted. In some cases, other sources give us a hint of what these adverse events likely are. For example,  one document states that "The most commonly reported [adverse events] included procedural pain, oropharyngeal pain, [REDACTED], cough, nasal congestion, and extremity pain," Luckily, one table below a nearly identical redacted section is intact, and it implies that the censored portion is drawn from the following: hypokalemia (low levels of potassium), vomiting, "balance disorder," headache, fever, back pain or a certain kind of blood clot known as a hematoma. (Vomiting and balance disorders are listed as possible side effects on eteplirsen's label.) In other cases, though, it's all but impossible to figure out what the FDA is attempting to block us from seeing: an updated listing of adverse events in a follow-up study says that "the most common [adverse events] overall were procedural pain [REDACTED.]" Also expunged from the document were possible indicators of kidney problems and issues related to blood clots. The FDA has to make an active decision to prevent the public from seeing what's behind those black bars in the document. And it's not just side effects where the FDA seems determined to prevent the public from getting the full picture about the scientific case for eteplirsen. *** A drug approval revolves around how patients perform with respect to so-called "outcome measures" in key clinical trials. Outcome measures are the yardsticks by which patient improvement is measured. For a muscle-wasting disease like DMD, there are many possible measures to choose from: how far a patient walks in six minutes, how long it takes to run 10 meters, how much time it takes to get up from the floor, and the like. However, it's crucial to choose those yardsticks ahead of time and publish the results from all of them; otherwise it's possible to game the system by "outcome switching." It's easy to make a worthless drug seem effective by hiding the outcome measures that don't show good results and publishing only outcomes that do. It's like going through a deck of cards and selecting only the ones you want; you're guaranteed a royal flush every time. Eteplirsen researchers observed at least nine outcome measures designed to gauge patients' muscle strength and tone. The results from at least two of these measures have been buried: they're missing from the peer-reviewed literature. That's not unexpected; drug companies and researchers do this all the time. But it's surprising that the FDA would be complicit in hiding buried outcomes. The agency censors all reference to the results of those measurements, and even to the names of the outcome measures that disappeared. Pretty much every mention of those two measures is blanked out. Tables: censored. Sarepta's evaluation of these outcome measures: censored. Even tables of contents: censored. From other sources, I have been able to piece together that the two missing outcome measures are a "nine-hole-peg test", in which a patient is timed putting pegs into holes, and the "MVICT," which measures the force with which a patient pulls against a strap. The results for these tests are nowhere to be found, even though they've been in Sarepta's hands for years. All my requests for the results of these missing measurements—from the researchers and from Sarepta itself—have been refused. And this is even though eteplirsen researchers apparently "presented" the results in a poster session at a meeting this October—not long after the FDA started handing over documents in response to my lawsuit. (Another poster presented at the same meeting is on Sarepta's Web site, yet there's nothing on the missing outcome measures.) Smart money is that the results of the nine-hole-peg test and MVICT have been redacted because they hurt eteplirsen's cause rather than help it. More evidence of outcome switching has to do with the number of certain types of white blood cells, known as CD3, CD4 and CD8 cells, found in each patient's muscle. It's not clear precisely what the researchers had in mind, because Sarepta's description of this "key secondary efficacy endpoint" on the national clinical trial registry Web site was vague. But we do know that sometime between July 201l, when the trial began, and July 2015, three years after it ended, the "key secondary efficacy endpoint" had mysteriously become a test of walking; the white-blood-cell outcome measure was nowhere to be found. (Neither the lead investigator of the eteplirsen trial nor Sarepta would answer questions about what the outcome measure was or what the results were.) FDA knows the answers, but it ain't telling: the major references to the analysis of these white blood cells tends to have a big block of censored text where the results should be. Outcome switching is a way for researchers and drug companies to distort the context around a clinical result, to make a drug look more effective or safe than it really is. The FDA's job is supposed to be exactly the opposite—to counter industry-distorted science and provide an objective measure of safety and effectiveness to help physicians make the best choices for their patients. Yet when it comes to eteplirsen, the FDA is siding squarely with the industry and against the public interest. This is even true when it comes to allegations of outright fraud. One of the most alarming documents to come out of my lawsuit is a chain of e-mails in which an FDA reviewer suggests that Sarepta or eteplirsen researchers might be manipulating and misrepresenting scientific images. Of most concern are so-called "Western blots." Scientists use Western blots—which, when photographed, look like a bunch of messy stripes—to gauge the types and amounts of protein in a sample. Western blot images are ubiquitous in the medical and biological literature, but because they're such simple images, they're easy to fake, and blot fraud is surprisingly common.   The eteplirsen studies had Western blots—and those images raised the eyebrows of an important FDA reviewer: "[T]here seems to be reason for concern of misrepresentation of the data," he wrote. Apparently, he was concerned that the images were misleading and perhaps even manipulated in an inappropriate way. Northwest Children's Hospital pediatrician and lead eteplirsen researcher Jerry Mendell denies allegations of manipulation of images. "The studies were FDA reviewed/audited [and the drug was approved] and the articles were peer reviewed," he wrote in an e-mail. Sarepta refused to discuss any allegations of misconduct. Who's right? It's impossible to tell. We can't say whether or not there's scientific misconduct without looking at the raw, unprocessed Western blot images and comparing them to the ones that are published. Mendell did not respond to requests for those unprocessed images. Nor did Sarepta. But those originals are in other hands, too. The FDA has them. They were originally embedded in the e-mail, but the agency didn't turn them over. It's possible that this is a technical issue, rather than an active attempt to prevent the public from seeing the data; I'm currently negotiating, through my lawyers, to get those images released. But the FDA certainly hasn't brought this issue to the public's attention; on the contrary, when pressed, FDA officials denied any suspicions of misconduct. (A different reviewer, several years later, said that he viewed the issue as "sloppy science" rather than misconduct.) And the FDA appears to be actively withholding similar data: another place where such raw images reside is redacted, as are major portions of the analysis that might cast light on how the data were processed. FDA won't release them. *** Why would the FDA block evidence of outcome switching, sit on possible evidence of scientific misconduct, and even hide references to a medication's side effects? The reasoning takes a bit of unpacking, but it boils down to a simple principle: FDA is refusing to release this information because it might hurt Sarepta, the maker of eteplirsen. The FDA has stated that the redacted sections represent "trade secrets and commercial or financial information obtained from a person and privileged or confidential." In this particular case, this tends to mean that the release of the information will cause "substantial competitive injury" to the company that turned it over to the FDA. Before releasing the documents, the agency allowed Sarepta (which is intervening in my lawsuit against the FDA) to suggest redactions that it felt would cause such harm or are exempt from release in other reasons. And sure enough, Sarepta thinks that releasing certain adverse events and endpoints will hurt Sarepta and help its competitors. (For example, Sarepta's present position is that releasing which endpoints were used, much less the results of the tests, would give "invaluable information to competitors.") If the agency didn't agree—if it didn't think that Sarepta was correct—it would still be required by law to release this information, or, at the very least to come up with a different reason for the redactions. So, to all appearances, the FDA believes that in these cases releasing this information will hurt Sarepta, and refuses to turn it over. That's it in a nutshell. The FDA is blocking access to very basic information about eteplirsen—censoring side effects, outcome measures and even possible evidence of misconduct—because releasing that information would hurt Sarepta. (The FDA refused to answer any of my questions about their conduct, citing the lawsuit as a reason.) The public's interest in knowing the truth about a drug is secondary to the interest in protecting a company from harm. This is toxic for our confidence in the FDA, and in the drugs that it allows to come to market. It may well be that there's no real case for scientific misconduct in the eteplirsen clinical trial. It may well be that we already know about all the drug's important side effects. Heck, it's even possible that the censored and missing outcome measures strengthen the case for the drug's effectiveness rather than weaken it. But FDA's willingness to consider such basic information about a drug's performance as a "trade secret" or “confidential commercial information" and block it from public view means that we won't—and can't—know. There's a haze of uncertainty around every single one of FDA's decisions. And this, ultimately was the trigger of the stock plunge at the end of September. When FDA made its adverse-events database easier to search, investors immediately started searching through it and turned up scary-seeming reports of deaths and injuries, which caused a loss in confidence about certain drugs—in Sarepta's case, about eteplirsen. (Sarepta's stock has since recovered.) Even though these adverse-events reports weren't terribly useful for evaluating the drugs' safety, every little scrap of new data can send shudders through a market starved for information. Had FDA been more scrupulous about serving the public's interest—sharing all information about adverse events, endpoint switching, and even intimations of fraud—the market wouldn't have been so reliant upon the noisy and hard-to-interpret data in the adverse-events database. The public would have much more confidence in an FDA that's truly transparent than one that is willing to call such information a "trade secret" or "confidential commercial information" and hide it from view. In other words, it's impossible to trust an agency that worries more about a drug's side effect on a company than on a patient. Charles Seife Charles Seife is a professor of journalism at New York University and author of Virtual Unreality: The New Era of Digital Deception (Penguin Books, 2014). Credit: Nick Higgins 0 minute ago  —  Daniel Barron November 29, 2017  —  Dan Robitzski and LiveScience 1 hour ago  —  Srikanth Saripalli and The Conversation US 1 hour ago  —  Leonard David and SPACE.com 15 hours ago  —  Larry Greenemeier 21 hours ago  —  Robert S. Siegler 

https://www.scientificamerican.com/article/is-the-fda-withholding-data-about-a-controversial-drug-to-protect-its-manufacturer/

In the case of Sarepta, it sure looks that way The Food and Drug Administration is seldom accused of being too transparent. But in late September, it looked like the agency had overshared. In an attempt to achieve the "greatest level of transparency," the agency caused the stock prices of four biotech companies to hemorrhage. Jittery traders, sifting through scraps of context-free information provided by the agency, dumped their drug stocks, triggering a brief but brutal plunge. It shouldn't have happened that way. The FDA's attempt at transparency was far from revolutionary; it was the release of a Web interface to a drug side-effects database known as FAERS. Not only was FAERS already public, albeit in a slightly less user-friendly form, the database is also messy, context-free and subject to all sorts of biases and errors, making it nigh impossible to interpret properly. It's not something that the public should be very excited about; FAERS certainly isn't a precise enough tool to tell market speculators whether to dump a stock, any more than a sledgehammer is a precise enough tool to amputate a limb. Yet soon after the FDA announced the new interface, the stocks of four companies—Sarepta, Ionis, Biogen, and Acadia—plunged. The underlying cause of the bloodbath, ironically, is the FDA's opacity regarding certain important data about the performance of drugs. Data about adverse events patients had when taking the drug. Data that can give us insight into what elements of a clinical study researchers haven't made public. Even data hinting at research misconduct in key drug trials. The agency refuses to release this data, yet without it, the public is unable make an informed decision about whether or not to take a drug. The reason: doing so might hurt a pharmaceutical company. FDA's refusal is a graphic demonstration of how the agency feels obliged to protect corporate secrets, even at the expense of consumer safety. That's the precise opposite of transparency, and in the FDA's case, it might be putting people's lives at risk. *** The FDA has the unenviable position of making life-and-death decisions every day. No matter how good the agency is, some of the time, it's going to get a decision wrong, and Americans will be put at risk and even die. When things go wrong, though, it's often damnably hard to figure out precisely what happened. The FDA has long had a reputation for opacity; even congresspeople, who have the power of subpoena, have been frustrated by the agency's refusal to provide basic information that could help reveal the true story behind a bad decision. A decade ago, Senator Charles Grassley (R-Iowa), when looking into a case where the FDA made a bad call in approving a dangerous drug, said the FDA put up "every excuse under the sun" to prevent the release of requested documents: “The Department [of Health and Human Services] and FDA say that they have been responsive to the Finance Committee's Ketek investigation because they made available millions of pages of documents to the Committee. But what they provided is quantity, not quality. “They delivered hundreds of pages simply marked, for example, ‘57 pages removed,’ or ‘43 pages removed.... Other documents have whole pages, paragraphs or sentences redacted with no explanation for what has been withheld or redacted and why. In fact, the FDA redacted some of the same documents differently and even redacted one of my own letters to them on a different matter....” Reporters like me have encountered similar roadblocks when covering the FDA. (For example, when I was trying to investigate how the agency was handling a massive case of fraud that undermined the data behind a number of approvals, the agency refused to release the names of the drugs that were affected.) On occasion, the agency is not just slow to release information about problems it's finding with drugs, but it has even been willing to reassure the public about products that later turn out to be dangerous. So the public can't rely upon the agency to release everything that's important to know, and objective data that the agency uses to make its decisions have become quite valuable for understanding not just the FDA's decision process but also whether it's been making good calls or bad ones. *** It so happens that one of the most controversial calls of the past few years has to do with one of the companies involved in September's stock plunge, Sarepta. A little over a year ago, the FDA decided to approve Sarepta's first drug, eteplirsen.  Eteplirsen is a cleverly designed compound that's supposed to help certain patients with Duchenne muscular dystrophy (DMD), a deadly disease that strikes young boys. Initially, the FDA's answer was that the drug should be rejected, but Janet Woodcock, the head of the agency's Center for Drug Evaluation and Research overruled the agency's own review team, a very unusual step, and declared that the drug should be allowed to come to market. Since then, a cloud has hung over eteplirsen as third parties, such as insurers, physicians and independent researchers, try to figure out whether or not the drug actually works. The agency has released thousands of pages of information about eteplirsen, but I knew that there was a lot of critical information missing from those pages—information that might help determine whether the agency approved an entirely ineffective drug based on faulty clinical trials and undue industry influence, or whether there is unjust suspicion about eteplirsen's safety and effectiveness. Earlier this year, I sued the FDA under the Freedom of Information Act to understand the eteplirsen decision better; the lawsuit was designed to force the agency to release information about the drug and the agency's decision. In the past several weeks, the agency has released thousands of pages of previously undisclosed documents about eteplirsen and its approval, and more are coming before the end of the year. Despite the volumes of papers the FDA is disclosing, once again, the FDA is far from transparent. What's so striking in those documents is not the information that FDA is releasing, but the information that the agency refuses to release.                 For example, in several of the documents, frequently encountered adverse events—side effects and other negative consequences that occur during a treatment—are occasionally redacted. In some cases, other sources give us a hint of what these adverse events likely are. For example,  one document states that "The most commonly reported [adverse events] included procedural pain, oropharyngeal pain, [REDACTED], cough, nasal congestion, and extremity pain," Luckily, one table below a nearly identical redacted section is intact, and it implies that the censored portion is drawn from the following: hypokalemia (low levels of potassium), vomiting, "balance disorder," headache, fever, back pain or a certain kind of blood clot known as a hematoma. (Vomiting and balance disorders are listed as possible side effects on eteplirsen's label.) In other cases, though, it's all but impossible to figure out what the FDA is attempting to block us from seeing: an updated listing of adverse events in a follow-up study says that "the most common [adverse events] overall were procedural pain [REDACTED.]" Also expunged from the document were possible indicators of kidney problems and issues related to blood clots. The FDA has to make an active decision to prevent the public from seeing what's behind those black bars in the document. And it's not just side effects where the FDA seems determined to prevent the public from getting the full picture about the scientific case for eteplirsen. *** A drug approval revolves around how patients perform with respect to so-called "outcome measures" in key clinical trials. Outcome measures are the yardsticks by which patient improvement is measured. For a muscle-wasting disease like DMD, there are many possible measures to choose from: how far a patient walks in six minutes, how long it takes to run 10 meters, how much time it takes to get up from the floor, and the like. However, it's crucial to choose those yardsticks ahead of time and publish the results from all of them; otherwise it's possible to game the system by "outcome switching." It's easy to make a worthless drug seem effective by hiding the outcome measures that don't show good results and publishing only outcomes that do. It's like going through a deck of cards and selecting only the ones you want; you're guaranteed a royal flush every time. Eteplirsen researchers observed at least nine outcome measures designed to gauge patients' muscle strength and tone. The results from at least two of these measures have been buried: they're missing from the peer-reviewed literature. That's not unexpected; drug companies and researchers do this all the time. But it's surprising that the FDA would be complicit in hiding buried outcomes. The agency censors all reference to the results of those measurements, and even to the names of the outcome measures that disappeared. Pretty much every mention of those two measures is blanked out. Tables: censored. Sarepta's evaluation of these outcome measures: censored. Even tables of contents: censored. From other sources, I have been able to piece together that the two missing outcome measures are a "nine-hole-peg test", in which a patient is timed putting pegs into holes, and the "MVICT," which measures the force with which a patient pulls against a strap. The results for these tests are nowhere to be found, even though they've been in Sarepta's hands for years. All my requests for the results of these missing measurements—from the researchers and from Sarepta itself—have been refused. And this is even though eteplirsen researchers apparently "presented" the results in a poster session at a meeting this October—not long after the FDA started handing over documents in response to my lawsuit. (Another poster presented at the same meeting is on Sarepta's Web site, yet there's nothing on the missing outcome measures.) Smart money is that the results of the nine-hole-peg test and MVICT have been redacted because they hurt eteplirsen's cause rather than help it. More evidence of outcome switching has to do with the number of certain types of white blood cells, known as CD3, CD4 and CD8 cells, found in each patient's muscle. It's not clear precisely what the researchers had in mind, because Sarepta's description of this "key secondary efficacy endpoint" on the national clinical trial registry Web site was vague. But we do know that sometime between July 201l, when the trial began, and July 2015, three years after it ended, the "key secondary efficacy endpoint" had mysteriously become a test of walking; the white-blood-cell outcome measure was nowhere to be found. (Neither the lead investigator of the eteplirsen trial nor Sarepta would answer questions about what the outcome measure was or what the results were.) FDA knows the answers, but it ain't telling: the major references to the analysis of these white blood cells tends to have a big block of censored text where the results should be. Outcome switching is a way for researchers and drug companies to distort the context around a clinical result, to make a drug look more effective or safe than it really is. The FDA's job is supposed to be exactly the opposite—to counter industry-distorted science and provide an objective measure of safety and effectiveness to help physicians make the best choices for their patients. Yet when it comes to eteplirsen, the FDA is siding squarely with the industry and against the public interest. This is even true when it comes to allegations of outright fraud. One of the most alarming documents to come out of my lawsuit is a chain of e-mails in which an FDA reviewer suggests that Sarepta or eteplirsen researchers might be manipulating and misrepresenting scientific images. Of most concern are so-called "Western blots." Scientists use Western blots—which, when photographed, look like a bunch of messy stripes—to gauge the types and amounts of protein in a sample. Western blot images are ubiquitous in the medical and biological literature, but because they're such simple images, they're easy to fake, and blot fraud is surprisingly common.   The eteplirsen studies had Western blots—and those images raised the eyebrows of an important FDA reviewer: "[T]here seems to be reason for concern of misrepresentation of the data," he wrote. Apparently, he was concerned that the images were misleading and perhaps even manipulated in an inappropriate way. Northwest Children's Hospital pediatrician and lead eteplirsen researcher Jerry Mendell denies allegations of manipulation of images. "The studies were FDA reviewed/audited [and the drug was approved] and the articles were peer reviewed," he wrote in an e-mail. Sarepta refused to discuss any allegations of misconduct. Who's right? It's impossible to tell. We can't say whether or not there's scientific misconduct without looking at the raw, unprocessed Western blot images and comparing them to the ones that are published. Mendell did not respond to requests for those unprocessed images. Nor did Sarepta. But those originals are in other hands, too. The FDA has them. They were originally embedded in the e-mail, but the agency didn't turn them over. It's possible that this is a technical issue, rather than an active attempt to prevent the public from seeing the data; I'm currently negotiating, through my lawyers, to get those images released. But the FDA certainly hasn't brought this issue to the public's attention; on the contrary, when pressed, FDA officials denied any suspicions of misconduct. (A different reviewer, several years later, said that he viewed the issue as "sloppy science" rather than misconduct.) And the FDA appears to be actively withholding similar data: another place where such raw images reside is redacted, as are major portions of the analysis that might cast light on how the data were processed. FDA won't release them. *** Why would the FDA block evidence of outcome switching, sit on possible evidence of scientific misconduct, and even hide references to a medication's side effects? The reasoning takes a bit of unpacking, but it boils down to a simple principle: FDA is refusing to release this information because it might hurt Sarepta, the maker of eteplirsen. The FDA has stated that the redacted sections represent "trade secrets and commercial or financial information obtained from a person and privileged or confidential." In this particular case, this tends to mean that the release of the information will cause "substantial competitive injury" to the company that turned it over to the FDA. Before releasing the documents, the agency allowed Sarepta (which is intervening in my lawsuit against the FDA) to suggest redactions that it felt would cause such harm or are exempt from release in other reasons. And sure enough, Sarepta thinks that releasing certain adverse events and endpoints will hurt Sarepta and help its competitors. (For example, Sarepta's present position is that releasing which endpoints were used, much less the results of the tests, would give "invaluable information to competitors.") If the agency didn't agree—if it didn't think that Sarepta was correct—it would still be required by law to release this information, or, at the very least to come up with a different reason for the redactions. So, to all appearances, the FDA believes that in these cases releasing this information will hurt Sarepta, and refuses to turn it over. That's it in a nutshell. The FDA is blocking access to very basic information about eteplirsen—censoring side effects, outcome measures and even possible evidence of misconduct—because releasing that information would hurt Sarepta. (The FDA refused to answer any of my questions about their conduct, citing the lawsuit as a reason.) The public's interest in knowing the truth about a drug is secondary to the interest in protecting a company from harm. This is toxic for our confidence in the FDA, and in the drugs that it allows to come to market. It may well be that there's no real case for scientific misconduct in the eteplirsen clinical trial. It may well be that we already know about all the drug's important side effects. Heck, it's even possible that the censored and missing outcome measures strengthen the case for the drug's effectiveness rather than weaken it. But FDA's willingness to consider such basic information about a drug's performance as a "trade secret" or “confidential commercial information" and block it from public view means that we won't—and can't—know. There's a haze of uncertainty around every single one of FDA's decisions. And this, ultimately was the trigger of the stock plunge at the end of September. When FDA made its adverse-events database easier to search, investors immediately started searching through it and turned up scary-seeming reports of deaths and injuries, which caused a loss in confidence about certain drugs—in Sarepta's case, about eteplirsen. (Sarepta's stock has since recovered.) Even though these adverse-events reports weren't terribly useful for evaluating the drugs' safety, every little scrap of new data can send shudders through a market starved for information. Had FDA been more scrupulous about serving the public's interest—sharing all information about adverse events, endpoint switching, and even intimations of fraud—the market wouldn't have been so reliant upon the noisy and hard-to-interpret data in the adverse-events database. The public would have much more confidence in an FDA that's truly transparent than one that is willing to call such information a "trade secret" or "confidential commercial information" and hide it from view. In other words, it's impossible to trust an agency that worries more about a drug's side effect on a company than on a patient. Charles Seife Charles Seife is a professor of journalism at New York University and author of Virtual Unreality: The New Era of Digital Deception (Penguin Books, 2014). Credit: Nick Higgins 0 minute ago  —  Daniel Barron November 29, 2017  —  Dan Robitzski and LiveScience 1 hour ago  —  Srikanth Saripalli and The Conversation US 1 hour ago  —  Leonard David and SPACE.com 15 hours ago  —  Larry Greenemeier 21 hours ago  —  Robert S. Siegler 

http://www.chicagotribune.com/news/nationworld/ct-nsa-army-data-cybersecurity-20171128-story.html

In this June 6, 2013 file photo, a sign stands outside the National Security Agency campus in Fort Meade, Md. In this June 6, 2013 file photo, a sign stands outside the National Security Agency campus in Fort Meade, Md. A cybersecurity company said Tuesday it found top secret files related to classified Army communications systems sitting unprotected online for anyone to see. The data belonged to the U.S. Army's Intelligence and Security Command, a division of both the Army and the National Security Agency. It's the latest known setback linked to the NSA where former agency contractor Edward Snowden disclosed a cache of classified material in 2013. NSA referred questions to the intelligence command, which did not immediately respond to a request for comment. Chris Vickery, an analyst at UpGuard, a cybersecurity company based in Mountain View, California, discovered the unprotected data online on Sept. 28. Vickery notified the government about what he had found and was told on Oct. 10 that it had been secured. "It is unclear to us what the precise relevance of the classified data we found is to active INSCOM operations," Dan O'Sullivan, another analyst on UpGuard's cyber risk team, said Tuesday. The data contained 47 files and folders that could be viewed, including three that could be downloaded. Some of the data could not be accessed without being linked to Pentagon systems, O'Sullivan said. Many files were marked "top secret" or "NOFORN," a classification that prohibits disclosure to foreign governments. The largest file contained a virtual hard drive likely designed for receiving Defense Department information from remote locations. The exposed data included sensitive details concerning a battlefield intelligence platform, known as the Distributed Common Ground System-Army, as well as the platform's troubled cloud auxiliary program codenamed "Red Disk." Snowden leaked classified material exposing U.S. government surveillance programs. In August 2016, Harold Thomas Martin III, 51, of Glen Burnie, Maryland, was arrested by the FBI after federal prosecutors say he illegally removed highly classified information and stored the material in his home and car. Reality Winner, 25, a former Air Force linguist who worked as an NSA contractor at a facility in Augusta, Georgia, was charged in June with copying a classified U.S. report and mailing it to a news organization. 

https://arstechnica.com/information-technology/2017/11/army-red-disk-intel-sharing-system-left-exposed-in-open-aws-data-store/

After uncovering a massive trove of social media-based intelligence left on multiple Amazon Web Services S3 storage buckets by a Defense Department contractor, the cloud security firm UpGuard has disclosed yet another major cloud storage breach of sensitive intelligence information. This time, the data exposed includes highly classified data and software associated with the Distributed Common Ground System-Army (DCGS-A), an intelligence distribution platform that DOD has spent billions to develop. Specifically, the breach involves software for a cloud-based component of DCGS-A called "Red Disk." The Red Disk system was developed under an "urgent operational need" program aimed at delivering intelligence to troops with tablets and laptop computers on the ground in Afghanistan via a cloud computing architecture. The initiative was never fully deployed—and it slowly became a symbol of how defense contractors were mining emergency war funds from the military. DCGS-A continues to be expanded and deployed by the Army after more than a decade of continuous development. UpGuard's director of cyber risk research, Chris Vickery, discovered the publicly accessible S3 storage "bucket" on September 27 in the AWS subdomain "inscom." INSCOM is the US Army's Intelligence and Security Command, the Army's internal operational intelligence branch based at Fort Belvoir in Virginia. INSCOM is also integrated into the National Security Agency's Central Security Service—connecting the Army's signals intelligence operations to the NSA. The public bucket was accessible via the Web and had "47 viewable files and folders in the main repository, three of which were also downloadable," UpGuard reported in a blog post today. The largest downloadable file was an Open Virtual Appliance file named “ssdev.ova,” which contained a virtual hard drive and configuration data for a Red Hat Linux-based virtual machine. "While the virtual OS and HD can be browsed in their functional states, most of the data cannot be accessed without connecting to Pentagon systems—an intrusion that malicious actors could have attempted had they found this bucket," UpGuard's research team noted. Still, the contents of the virtual hard drive itself were highly sensitive. Some of the files were marked as "Top Secret/NOFORN"—meaning that they were not to be shared even with US allies. Metadata on the virtual drive shows that "the box was worked on in some capacity by a now-defunct third-party defense contractor named Invertix, a known INSCOM partner," including private encryption keys used for hashed passwords and for accessing DCGS that belonged to Invertix system administrators. A screenshot of the directory list for the virtual drive also shows that the virtual appliance is configured with client code for Apache Accumulo, the key-value data store with cell-level security originally developed by the NSA (it's based on Google's BigTable). Other items on the virtual drive's partition suggest that the .ova was for an operator training virtual machine, including what appears to be training system software from the UK-based defense software company SyntheSys. Other items accessible for download include a "ReadMe" document with instructions on how to use the .ova file and the location of other Red Disk installation packages and a Java .jar file that "appears to constitute a training snapshot for labeling and categorizing classified information, as well as assigning such data to 'regions,'" UpGuard noted. The training package could be used by an adversary to access and analyze data with the virtual appliance. The mishandling of sensitive information in the cloud by military contractors has been an ever-expanding problem for the DOD and NSA. In September, UpGuard alerted DOD contractor TigerSwan that a former recruiting vendor had left the resumes of job applicants—including their security clearance data—in a misconfigured S3 storage bucket. And earlier this month, UpGuard revealed that VendorX, a company that provides a "multilingual social analytics platform" called Outpost to the DOD and Intelligence community, had left several S3 buckets with social media clippings publicly accessible. In each of these cases, the leaks were caused by simple misconfiguration of permissions for the AWS virtual storage accounts. And as UpGuard's researchers noted, these problems are likely indicative of a much broader process issue among both government contractors and agencies themselves. "Given how simple the immediate solution to such an ill-conceived configuration is—simply update the S3 bucket’s permission settings to only allow authorized administrators access—the real question is, 'how can government agencies keep track of all their data and ensure they are correctly configured and secured?'" researchers wrote. The answer seems to be fairly straightforward for systems like Red Disk—such items should probably never be put in a public cloud service at all. 

https://techcrunch.com/2017/11/28/army-nsa-inscom-aws-leak/

In the latest edition of “uh-oh, we left that just sitting out in the open,” a batch of NSA and Army files were discovered on a cloud storage server with no password protection, accessible to anyone with the URL. Chris Vickery of security firm UpGuard found the files on an unlisted Amazon Web Services S3 cloud storage server belonging to the United States Army Intelligence and Security Command (INSCOM), an intelligence gathering and security command that operates jointly out of the U.S. Army and the NSA. Within the bucket of data, Vickery found 47 viewable files and three downloadable files, some of which contained information designated as “Top Secret” or “NOFORN,” a security term that stipulates that material should not be shared with foreign allies. As UpGuard’s report details, Vickery also found “a virtual hard drive used for communications within secure federal IT environments” and “details concerning the Defense Department’s battlefield intelligence platform” known as DCGS-A and information on Red Disk, “a troubled Defense Department cloud intelligence platform” that integrates into Red Disk. The breach also included private keys belonging to Invertix, a defense contractor that works with INSCOM. The files in question were stored on a subdomain labeled “INSCOM.” “Although the UpGuard Cyber Risk Team has found and helped to secure multiple data exposures involving sensitive defense intelligence data, this is the first time that clearly classified information has been among the exposed data,” UpGuard notes. This kind of misconfigured storage server is becoming a common cautionary tale in the security world lately. Earlier this year, the same researcher discovered a set of sensitive files belonging to defense contractor Booz Allen Hamilton left out on a similarly unsecured server. Of course, the issue isn’t that security firms are digging up these unprotected pockets of classified material, it’s that we have no way of knowing who else is. 

https://www.cnet.com/news/nsa-breach-spills-over-100gb-of-top-secret-data/

The latest NSA data breach leaked more than 100 GB of data.  The National Security Agency still hasn't fixed its leaking problem.  A virtual disk image belonging to the NSA -- essentially the contents of a hard drive -- was left exposed on a public Amazon Web Services storage server. The server contained more than 100 gigabytes of data from an Army intelligence project codenamed "Red Disk," ZDNet first reported.  The server was unlisted, but it didn't have a password, which meant that anyone who found it could dig through the government's secret documents. That's exactly what happened in late September when Chris Vickery, director of cyber risk research at security company UpGuard, discovered the server. He alerted the government in October. It was on the AWS subdomain "inscom," an abbreviation for the US Army Intelligence and Security Command.  "It was as simple as typing in a URL," Vickery said. "This data was top secret classification, as well as files obviously related to US intelligence networks. It's stuff used to target people for death, and it was all available in a URL." Vickery said it had been so unbelievably easy to access that when he first discovered it, his first thought was, "is this real?"  Data breaches from both AWS servers and the NSA have become a common in recent years. Poor security on AWS servers led to exposed data tied to the Pentagon, Verizon, Dow Jones and nearly 200 million American voter records.  The NSA, meanwhile, has suffered notorious leaks dating back to Edward Snowden's whistle-blowing in 2013 on the agency's massive surveillance program. Since then, thieves have stolen the NSA's hacking tools, and an NSA contractor faced charges after leaking the agency's secrets to the public. Another contractor faces up to 11 years in prison for stealing top secret documents. The agency did not respond to a request for comment. Data theft from the NSA can lead to serious collateral damage. The massive WannaCry ransomware attack spread rapidly because hackers took advantage of a stolen NSA tool.  A look at some of the files stored on the AWS server.  In the latest incident, the contents on the insecure AWS server are classified as "NOFORN," meaning the information is sensitive enough that even foreign allies are not allowed to see it, UpGuard said. The server contained 47 viewable files, three of which were downloadable and exposed national security data. Most of the data couldn't be accessed without connecting to the Pentagon's network, the security firm's researchers said.  ZDNet was able to get a look at some of the files, and spotted a connection to Red Disk, a cloud-based intelligence system developed by the Army in 2013. Red Disk, a $93 million program considered a military failure, was designed to help the Pentagon with soldiers on the field collecting classified reports, drone footage and satellite images. The data all belonged to INSCOM, a division of both the Army and the NSA. "Plainly put, the digital tools needed to potentially access the networks relied upon by multiple Pentagon intelligence agencies to disseminate information should not be something available to anybody entering a URL into a web browser," UpGuard said in a blog post.   Security:  Stay up-to-date on the latest in breaches, hacks, fixes and all those cybersecurity issues that keep you up at night.  iHate: CNET looks at how intolerance is taking over the internet. 

